Work Diary

week2
Group formed. After discussion in the lab, we had an agreement about which topic we will do. According to the given three topic, we decided to attempt the topic 1 - X-o-Bot. After the lab, I tried to search some information about chat robot on the internet. Finally, I found a python library called "ChatterBot" which will be very useful for our project and I recommended it to my teammate.

week3
In this week, we have a discussion about the project proposal in the lab and split the project to three parts which are database, chat robot and user interface. For me, I will do the database system and make a connection to the robot part. I complete the epic about database system module in the project proposal and decide to use MySQL as the database management system. In the lab, we also discuss what the queries category will be such as subject requirements, course information and degree information. So in the next week, I will do the information retrieval and web search for providing data to the database system.

week4
In this week, I try to crawl some course information in postgraduate coursework from UNSW 2018 handbook website. As I am not familiar with the spider tools, I do some research on the Internet. I found that there is an open source and collaborative framework called "Scrapy" which is fast and simple for extracting the data from the websites. Then I read the documentation about this framework and started the project. Now I have completed the extraction of some main course information such as course code, course title and course credit. The code of this part has been uploaded to the GitHub. In the next week, I will extract some detail information about all courses. If time available, I will try to save the information to the database system.

week5
In week 4, I have crawled all the course information about code, title and credit. So in this week, I continue do the web research on the UNSW handbook 2018 postgraduate website for detail information about every course including faculty, school, campus and so on. For most courses, the detailed information has been crawled. There are still some errors in the code. Some are caused by website information loss and the other are caused by information saving. I will solve these problem in the next week. Furthermore, I will also crawl the course information about undergraduate.

week6
The websites of UNSW handbook have been totally changed and the structure has been changed as well. So the code we developed before needed to be rewrite. However, the data we has crawled could still be used. In this week, I tried to write new code to parse the new websites.

week7
In this week, I am still working with the database module. In the weeks before, I crawled the information from UNSW handbook websites and saved the data in CSV files which are convenient for my teammates to use the data. However, if we want to crawl huge information from the websites, the CSV file could not satisfy the demand. So the database system should be implemented. This week, I have built the database development environment and successfully saved the information to the database system.
